<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Publications - Trustworthy Intelligence Lab</title>
    <link rel="stylesheet" href="style/styles.css">
</head>
<body>
    <header>
        <nav class="container">
            <a href="index.html" class="logo">TI Lab</a>
            <ul class="nav-links">
                <li><a href="index.html">Home</a></li>
                <li><a href="index.html#about">About</a></li>
                <li><a href="team.html">Team</a></li>
                <li><a href="publications.html">Publications</a></li>
                <li><a href="index.html#projects">Projects</a></li>
                <li><a href="index.html#contact">Contact</a></li>
                <li><button class="theme-toggle" onclick="toggleTheme()">ðŸŒ™ Dark Mode</button></li>
            </ul>
        </nav>
    </header>

    <main>
        <section class="hero">
            <div class="container">
                <h1>Publications</h1>
                <p>Our latest research contributions to trustworthy intelligence</p>
            </div>
        </section>

        <section class="about">
            <div class="container">
                <h2>2025 Publications</h2>
                <div class="publication-list">
                    <div class="publication-item">
                        <h3 class="publication-title">Robust Vision Transformers: Defending Against Adversarial Attacks in Critical Applications</h3>
                        <p class="publication-authors">A. Chen, S. Williams, E. Rodriguez, J. Liu</p>
                        <p class="publication-venue">IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2025)</p>
                        <p class="publication-abstract">We present a comprehensive framework for enhancing the adversarial robustness of Vision Transformers in safety-critical applications. Our approach combines adversarial training with architectural modifications to achieve state-of-the-art robustness while maintaining competitive accuracy.</p>
                        <div class="publication-links">
                            <a href="#" class="publication-link">PDF</a>
                            <a href="#" class="publication-link">Code</a>
                            <a href="#" class="publication-link">Bibtex</a>
                        </div>
                    </div>

                    <div class="publication-item">
                        <h3 class="publication-title">Interpretable Medical Image Analysis: A Multi-Modal Approach to Trustworthy Diagnosis</h3>
                        <p class="publication-authors">J. Liu, S. Williams, P. Patel, A. Chen</p>
                        <p class="publication-venue">Medical Image Computing and Computer Assisted Intervention (MICCAI 2025)</p>
                        <p class="publication-abstract">This work introduces a novel interpretable framework for medical image analysis that combines multiple imaging modalities while providing clinicians with transparent decision explanations. Our method achieves superior diagnostic accuracy while maintaining full interpretability.</p>
                        <div class="publication-links">
                            <a href="#" class="publication-link">PDF</a>
                            <a href="#" class="publication-link">Code</a>
                            <a href="#" class="publication-link">Dataset</a>
                            <a href="#" class="publication-link">Bibtex</a>
                        </div>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <footer id="contact">
        <div class="container">
            <p>&copy; 2025 Trustworthy Intelligence Lab. All rights reserved.</p>
            <p>Advancing the future of trustworthy intelligence</p>
        </div>
    </footer>

    <script src="style/script.js"></script>
</body>
</html>
